"""
åŸºç¡€è®¾æ–½åˆå§‹åŒ–è„šæœ¬
åˆ›å»º Qdrant Collectionã€Elasticsearch Index ç­‰
è¿è¡Œæ–¹å¼: python -m scripts.init_infrastructure
"""

import asyncio
import sys
import httpx
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance, VectorParams, HnswConfigDiff,
    OptimizersConfigDiff, PayloadSchemaType,
)

sys.path.insert(0, ".")
from config.settings import settings


def init_qdrant():
    """åˆ›å»º Qdrant å‘é‡é›†åˆ"""
    print("ğŸ”§ Initializing Qdrant collection...")

    client = QdrantClient(
        host=settings.qdrant_host,
        port=settings.qdrant_port,
    )

    collection_name = settings.qdrant_collection_name

    # å¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡
    collections = [c.name for c in client.get_collections().collections]
    if collection_name in collections:
        print(f"  â© Collection '{collection_name}' already exists, skipping.")
        return

    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(
            size=settings.embedding_dimension,  # BGE-M3: 1024
            distance=Distance.COSINE,
        ),
        hnsw_config=HnswConfigDiff(
            m=16,                   # HNSW è¿æ¥æ•°ï¼ˆå¹³è¡¡ç²¾åº¦å’Œå†…å­˜ï¼‰
            ef_construct=100,       # æ„å»ºæ—¶çš„æœç´¢å®½åº¦
        ),
        optimizers_config=OptimizersConfigDiff(
            indexing_threshold=20000,   # è¶…è¿‡ 2 ä¸‡æ¡åå¯åŠ¨ç´¢å¼•ä¼˜åŒ–
        ),
    )

    # åˆ›å»º payload ç´¢å¼•ï¼ˆç”¨äºå…ƒæ•°æ®è¿‡æ»¤ï¼‰
    for field, schema_type in [
        ("doc_id", PayloadSchemaType.KEYWORD),
        ("doc_type", PayloadSchemaType.KEYWORD),
        ("chunk_type", PayloadSchemaType.KEYWORD),
        ("is_latest", PayloadSchemaType.BOOL),
        ("group_id", PayloadSchemaType.KEYWORD),
    ]:
        client.create_payload_index(
            collection_name=collection_name,
            field_name=field,
            field_schema=schema_type,
        )

    info = client.get_collection(collection_name)
    print(f"  âœ… Collection '{collection_name}' created. "
          f"Vector dim={info.config.params.vectors.size}")


def init_elasticsearch():
    """åˆ›å»º Elasticsearch ç´¢å¼•ï¼ˆå¸¦ IK ä¸­æ–‡åˆ†è¯ï¼‰"""
    print("ğŸ”§ Initializing Elasticsearch index...")

    index_name = settings.es_index_name

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
    resp = httpx.head(f"{settings.es_host}/{index_name}")
    if resp.status_code == 200:
        print(f"  â© Index '{index_name}' already exists, skipping.")
        return

    index_config = {
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0,        # å¼€å‘ç¯å¢ƒå•èŠ‚ç‚¹
            "analysis": {
                "analyzer": {
                    "ik_smart_analyzer": {
                        "type": "custom",
                        "tokenizer": "ik_smart",
                    },
                    "ik_max_analyzer": {
                        "type": "custom",
                        "tokenizer": "ik_max_word",
                    },
                },
            },
        },
        "mappings": {
            "properties": {
                # æ–‡æœ¬å†…å®¹ - ä½¿ç”¨ IK åˆ†è¯
                "content": {
                    "type": "text",
                    "analyzer": "ik_max_word",          # ç´¢å¼•æ—¶æœ€å¤§ç²’åº¦åˆ†è¯
                    "search_analyzer": "ik_smart",       # æœç´¢æ—¶æ™ºèƒ½åˆ†è¯
                },
                # ç« èŠ‚è·¯å¾„ - åŒæ—¶æ”¯æŒç²¾ç¡®åŒ¹é…å’Œåˆ†è¯æœç´¢
                "section_path": {
                    "type": "text",
                    "analyzer": "ik_smart",
                    "fields": {
                        "keyword": {"type": "keyword"},
                    },
                },
                # å…ƒæ•°æ®å­—æ®µ - keyword ç±»å‹ï¼ˆç²¾ç¡®åŒ¹é… + è¿‡æ»¤ï¼‰
                "chunk_id":    {"type": "keyword"},
                "doc_id":      {"type": "keyword"},
                "doc_title":   {
                    "type": "text",
                    "analyzer": "ik_smart",
                    "fields": {
                        "keyword": {"type": "keyword"},
                    },
                },
                "doc_type":    {"type": "keyword"},
                "group_id":    {"type": "keyword"},
                "chunk_type":  {"type": "keyword"},
                "is_latest":   {"type": "boolean"},
                "page_numbers": {"type": "integer"},
                "chunk_index": {"type": "integer"},
                "token_count": {"type": "integer"},
                "created_at":  {"type": "date"},
            },
        },
    }

    resp = httpx.put(
        f"{settings.es_host}/{index_name}",
        json=index_config,
    )
    resp.raise_for_status()
    print(f"  âœ… Index '{index_name}' created with IK analyzer.")


def main():
    print("=" * 60)
    print("DocAI Platform - Infrastructure Initialization")
    print("=" * 60)

    try:
        init_qdrant()
    except Exception as e:
        print(f"  âŒ Qdrant init failed: {e}")

    try:
        init_elasticsearch()
    except Exception as e:
        print(f"  âŒ Elasticsearch init failed: {e}")

    print("=" * 60)
    print("Done! Run verify script to check: python -m scripts.verify_services")
    print("=" * 60)


if __name__ == "__main__":
    main()
